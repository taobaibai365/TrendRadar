#!/usr/bin/env python3
# coding=utf-8
"""
åˆ†ç»„æ¶æ„æµ‹è¯•è„šæœ¬

æµ‹è¯•æ•°æ®æºåˆ†ç»„ç®¡ç†å™¨å’Œæœ¬åœ°æ•°æ®æºçš„åŸºæœ¬åŠŸèƒ½ã€‚
"""

import os
import sys
import tempfile
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from trendradar.sources import (
    SourceGroupManager,
    SourceGroup,
    AIConfig,
    LocalSource,
    SourceConfig,
    SourceType
)


def test_source_group_manager():
    """æµ‹è¯•æ•°æ®æºåˆ†ç»„ç®¡ç†å™¨"""
    print("=" * 60)
    print("æµ‹è¯• 1: æ•°æ®æºåˆ†ç»„ç®¡ç†å™¨")
    print("=" * 60)

    # åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶
    with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
        config_path = f.name
        f.write("""
source_groups:
  - id: "network"
    name: "ç½‘ç»œä¿¡æ¯æº"
    enabled: true
    ai_config:
      provider: "openai"
      model_name: "gpt-4o-mini"
    sources:
      - type: "rss"
        id: "test-rss"
        name: "æµ‹è¯•RSS"
        url: "https://example.com/feed/"
        enabled: true

  - id: "inbox"
    name: "éšæ‰‹æ”¶é›†"
    enabled: true
    sources: []
""")

    try:
        # æµ‹è¯•åŠ è½½é…ç½®
        print("\n1.1 åŠ è½½é…ç½®...")
        manager = SourceGroupManager(config_path)
        groups = manager.get_all_groups()
        print(f"âœ“ åŠ è½½äº† {len(groups)} ä¸ªåˆ†ç»„")

        for group in groups:
            print(f"  - {group.name} (ID: {group.id}, å¯ç”¨: {group.enabled})")
            if group.ai_config:
                print(f"    AI: {group.ai_config.provider}/{group.ai_config.model_name}")

        # æµ‹è¯•è·å–å•ä¸ªåˆ†ç»„
        print("\n1.2 è·å–å•ä¸ªåˆ†ç»„...")
        network = manager.get_group("network")
        if network:
            print(f"âœ“ æ‰¾åˆ°åˆ†ç»„: {network.name}")
            print(f"  æ•°æ®æºæ•°é‡: {len(network.sources)}")

        # æµ‹è¯•æ·»åŠ åˆ†ç»„
        print("\n1.3 æ·»åŠ æ–°åˆ†ç»„...")
        new_group = SourceGroup(
            id="test",
            name="æµ‹è¯•åˆ†ç»„",
            enabled=True,
            ai_config=AIConfig(provider="openai", model_name="gpt-4o-mini"),
            sources=[]
        )
        success = manager.add_group(new_group)
        if success:
            print(f"âœ“ æˆåŠŸæ·»åŠ åˆ†ç»„: {new_group.name}")

        # æµ‹è¯•ä¿å­˜é…ç½®
        print("\n1.4 ä¿å­˜é…ç½®...")
        success = manager.save_config()
        if success:
            print(f"âœ“ é…ç½®å·²ä¿å­˜åˆ° {config_path}")

        print("\nâœ… æ•°æ®æºåˆ†ç»„ç®¡ç†å™¨æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(config_path):
            os.unlink(config_path)


def test_local_source():
    """æµ‹è¯•æœ¬åœ°æ•°æ®æº"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 2: æœ¬åœ°æ•°æ®æº")
    print("=" * 60)

    # åˆ›å»ºä¸´æ—¶ç›®å½•å’Œæµ‹è¯•æ–‡ä»¶
    with tempfile.TemporaryDirectory() as temp_dir:
        print(f"\n2.1 åˆ›å»ºæµ‹è¯•ç›®å½•: {temp_dir}")

        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        test_files = {
            "test1.md": """# æµ‹è¯•æ–‡æ¡£1

è¿™æ˜¯ç¬¬ä¸€ç¯‡æµ‹è¯•æ–‡æ¡£çš„å†…å®¹ã€‚

## è¦ç‚¹

- è¦ç‚¹1
- è¦ç‚¹2
- è¦ç‚¹3
""",
            "test2.txt": """æµ‹è¯•æ–‡æ¡£2

è¿™æ˜¯ä¸€ç¯‡çº¯æ–‡æœ¬æ–‡æ¡£ã€‚

åŒ…å«ä¸€äº›å†…å®¹ç”¨äºæµ‹è¯•ã€‚
""",
            "test3.md": """# é¡¹ç›®æ–‡æ¡£

è¿™æ˜¯ä¸€ä¸ªé¡¹ç›®ç›¸å…³çš„æ–‡æ¡£ã€‚

## èƒŒæ™¯

æè¿°é¡¹ç›®çš„èƒŒæ™¯ä¿¡æ¯ã€‚

## ç›®æ ‡

åˆ—å‡ºé¡¹ç›®çš„ä¸»è¦ç›®æ ‡ã€‚
"""
        }

        for filename, content in test_files.items():
            filepath = os.path.join(temp_dir, filename)
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"  âœ“ åˆ›å»ºæ–‡ä»¶: {filename}")

        try:
            # åˆ›å»ºæœ¬åœ°æ•°æ®æºé…ç½®
            print("\n2.2 åˆ›å»ºæœ¬åœ°æ•°æ®æº...")
            config = SourceConfig(
                id="test-local",
                name="æµ‹è¯•æœ¬åœ°æº",
                type=SourceType.LOCAL,
                enabled=True,
                max_items=10,
                extra={
                    "path": temp_dir,
                    "file_patterns": ["*.md", "*.txt"],
                    "recursive": False
                }
            )

            # åˆ›å»ºæ•°æ®æºå¹¶æŠ“å–
            print("\n2.3 æŠ“å–æ–‡ä»¶...")
            source = LocalSource(config)
            articles = source.fetch()

            print(f"âœ“ æŠ“å–åˆ° {len(articles)} ä¸ªæ–‡ä»¶")

            # æ˜¾ç¤ºæŠ“å–ç»“æœ
            print("\n2.4 æŠ“å–ç»“æœ:")
            for i, article in enumerate(articles, 1):
                print(f"\n  æ–‡ä»¶ {i}:")
                print(f"    æ ‡é¢˜: {article.title}")
                print(f"    è·¯å¾„: {article.url}")
                print(f"    ç±»å‹: {article.source_type}")
                print(f"    å†…å®¹é•¿åº¦: {len(article.content) if article.content else 0}")
                if article.content:
                    preview = article.content[:100].replace('\n', ' ')
                    print(f"    é¢„è§ˆ: {preview}...")

            print("\nâœ… æœ¬åœ°æ•°æ®æºæµ‹è¯•é€šè¿‡")
            return True

        except Exception as e:
            print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False


def test_ai_config():
    """æµ‹è¯•AIé…ç½®"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 3: AIé…ç½®")
    print("=" * 60)

    try:
        # æµ‹è¯•åˆ›å»ºAIé…ç½®
        print("\n3.1 åˆ›å»ºAIé…ç½®...")
        config = AIConfig(
            provider="openai",
            api_key="sk-test",
            model_name="gpt-4o-mini",
            temperature=0.7
        )
        print(f"âœ“ åˆ›å»ºé…ç½®: {config.provider}/{config.model_name}")

        # æµ‹è¯•è½¬æ¢ä¸ºå­—å…¸
        print("\n3.2 è½¬æ¢ä¸ºå­—å…¸...")
        config_dict = config.to_dict()
        print(f"âœ“ è½¬æ¢æˆåŠŸ: {config_dict}")

        # æµ‹è¯•ä»å­—å…¸åˆ›å»º
        print("\n3.3 ä»å­—å…¸åˆ›å»º...")
        config2 = AIConfig.from_dict(config_dict)
        print(f"âœ“ åˆ›å»ºæˆåŠŸ: {config2.provider}/{config2.model_name}")

        # æµ‹è¯•ä¸ç¯å¢ƒå˜é‡ç»“åˆ
        print("\n3.4 ç¯å¢ƒå˜é‡æ”¯æŒ...")
        os.environ['TEST_API_KEY'] = 'sk-from-env'
        config_with_env = AIConfig(
            provider="openai",
            api_key="${TEST_API_KEY}",
            model_name="gpt-4o"
        )
        print(f"âœ“ API Key: {config_with_env.api_key}")

        print("\nâœ… AIé…ç½®æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "=" * 60)
    print("TrendRadar åˆ†ç»„æ¶æ„æµ‹è¯•")
    print("=" * 60)

    results = {
        "æ•°æ®æºåˆ†ç»„ç®¡ç†å™¨": test_source_group_manager(),
        "æœ¬åœ°æ•°æ®æº": test_local_source(),
        "AIé…ç½®": test_ai_config(),
    }

    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)

    passed = 0
    failed = 0

    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
        else:
            failed += 1

    print(f"\næ€»è®¡: {passed} é€šè¿‡, {failed} å¤±è´¥")

    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        return 0
    else:
        print(f"\nâš ï¸  æœ‰ {failed} ä¸ªæµ‹è¯•å¤±è´¥")
        return 1


if __name__ == "__main__":
    sys.exit(main())
